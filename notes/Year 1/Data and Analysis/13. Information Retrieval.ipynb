{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "\n",
    "Unstructured data generally means no additional or data-specific structure, for example:\n",
    "\n",
    "| Data type | | Analysis |\n",
    "| :--- | :--- | :--- |\n",
    "| Plain text | No structure beyond a sequence of characters. | Use of POS and syntax trees to add structure |\n",
    "| Graphics, photos, audio, video | A stream of values (bits, colors, pressure levels) in one or more dimensions. File formats and compression techniques may be structured, but the raw data is not. | Within the data we could use object recognition, or sound filtering |\n",
    "| Sensor data, experimental results| Observational data. | Applying statisitical tests to confirm or refute a hypothesis |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infomation Retrieval\n",
    "An _infomation retrieval (IR)_ task is, given a query, find the relevent documents in a collection. This assumes:\n",
    "- Their is a large collection to be searched\n",
    "- Their is a query (often keywords) to search for\n",
    "- The task is to find all and only the relevent documents\n",
    "\n",
    "An example would be searching a library catologue, if the user supplys the authors name the catalogue should list all books by that author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR Evaluation\n",
    "To evaluate the performance of an IR systems their are two measures, precision and recall.\n",
    "\n",
    "- __Precision:__ The proportion of the documents returned by the system that are relevant.\n",
    "- __Recall:__ The proportion of all the relevant documents that are returned by the system.\n",
    "\n",
    "We can further break this down into 4 measures:\n",
    "- __True positives (TP):__ Number of relevant documents retrieved.\n",
    "- __False positives (FP):__ Number of non-relevant documents retrived.\n",
    "- __True negatives (TN):__ Number of non-relevant documents not retrived.\n",
    "- __False negatives (FN):__ Number of relevant documents not retrived.\n",
    "\n",
    "This gives us the following statisitcs for precision (P) and recall (R):\n",
    "$$\n",
    "P = \\dfrac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R = \\dfrac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "#### Example\n",
    "> Their are 130 documents, system 1 returns 25 of which 16 are relevant, system 2 returns 15 of which 12 are relevant.\n",
    "\n",
    "__System 1__\n",
    "\n",
    "| | Relevant | Not Relevant | Total |\n",
    "| :--- | --- | --- |\n",
    "| Retrieved | 16 | 9 | 25 |\n",
    "| Not Retrieved | 12 | 93 | 105 |\n",
    "| Total | 28 | 102 | 130 |\n",
    "\n",
    "$$\n",
    "P = \\dfrac{16}{16 + 9} = 0.64\n",
    "$$\n",
    "\n",
    "$$\n",
    "R = \\dfrac{16}{16 + 12} = 0.57\n",
    "$$\n",
    "\n",
    "__System 2__\n",
    "\n",
    "| | Relevant | Not Relevant | Total |\n",
    "| :--- | --- | --- |\n",
    "| Retrieved | 12 | 3 | 15 |\n",
    "| Not Retrieved | 16 | 99 | 115 |\n",
    "| Total | 28 | 102 | 130 |\n",
    "\n",
    "$$\n",
    "P = \\dfrac{12}{12 + 3} = 0.80\n",
    "$$\n",
    "\n",
    "$$\n",
    "R = \\dfrac{12}{12 + 16} = 0.43\n",
    "$$\n",
    "\n",
    "System 2 is more precise, but system 1 has a higher recall.\n",
    "\n",
    "#### F-score\n",
    "AN F-score is an evaluation measure that combines precision and recall.\n",
    "$$\n",
    "F_\\alpha = \\dfrac{1}{\\dfrac{\\alpha}{P} + \\dfrac{1 - \\alpha}{R}}\n",
    "$$\n",
    "$\\alpha$ is a weighting factor, values of $\\alpha$ closer to $1$ value precision higher, values closer to $0$ value recall heigher.\n",
    "\n",
    "Comparing the systems from the example above with $\\alpha = 0.5$\n",
    "\n",
    "$$\n",
    "F_{0.5}(\\text{System 1}) = \\dfrac{1}{\\dfrac{0.5}{0.64} + \\dfrac{1 - 0.5}{0.57}} = 0.60\n",
    "$$\n",
    "\n",
    "$$\n",
    "F_{0.5}(\\text{System 2}) = \\dfrac{1}{\\dfrac{0.5}{0.80} + \\dfrac{1 - 0.5}{0.43}} = 0.56\n",
    "$$\n",
    "\n",
    "So a balanced F-score rates system 1 slightly better than system 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
