{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Corpora\n",
    "\n",
    "Corpora can answer empirical linguist and congnitive science questions:\n",
    "- Corpora can be analyzed using statistical tools.\n",
    "- Hypotheses about language processing and acquisition can be tested.\n",
    "- New facts about language structure can be discoverd.\n",
    "\n",
    "Corpora can be used to engineer natural-language systems in AI and computer science:\n",
    "- Corpora represents the data that systems have to handle.\n",
    "- Algorithms can find and extract regularities from corpus data.\n",
    "- Text-based or speech-based computer applications can learn automatically from corpus data.\n",
    "- Natural language processing\n",
    "    - Summarization: Producing a summary from a large text.\n",
    "    - Machine Translation (MT): Translation between two languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations\n",
    "A collocation is a sequence of words that occor together, for example:\n",
    "- \"run amok\", the verb \"run\" can occor on its own, but \"amok\" does not.\n",
    "- \"strong tea\" is natural English, but \"powerful tea\" is not even though the meaning is the same.\n",
    "- \"heated argument\", \"commit a crime\", etc\n",
    "\n",
    "Collocations are usefull for learning languages, and language analysis so finding them is an important problem. We cant just look at a list of bigrams however since most will not be collocations. For example \"strong and\" is not a collocation, and is a connective however \"strong bear\" is but it may be alot less frequent. One way to find collocations is statistics, speciffically contingency tables:\n",
    "\n",
    "| | \"beer\" | ¬\"beer | Total |\n",
    "| :--- | --- | --- | --- |\n",
    "| __\"strong\"__ | 7 | 618 | 625 |\n",
    "| __¬\"strong\"__ | 127 | 2310422 | 2310549 |\n",
    "| __Total__ | 134 | 2311040 | 2311174 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation\n",
    "Machine translation has two major approaches, rule-based translation and statisitcal translation.\n",
    "\n",
    "#### Rule-Based Machine Translation (RBMT)\n",
    "A RBMT scheme is often follows three steps:\n",
    "1. Automatic POS tagging.\n",
    "2. Parsing the text to produce a syntax tree using grammatical rules.\n",
    "3. Map the parse tree to the target language using a dictionary to translate words and syntax tree to rearrange the sentence.\n",
    "\n",
    "The problem with rule-based translation is that difficulty of identifiying all the nuances of natural language, often translations fell unnatural even though the content may be correct.\n",
    "\n",
    "#### Statistical machine translation\n",
    "By analysining _parralel texts_ (the same text written in two languages), machines can produce much more natural sounding translations. The process is as follows:\n",
    "1. For every word and phrase, find all occorances in the corpus\n",
    "2. Mathc the words and phrases with the parallel corpus text. \n",
    "3. Use statisital methods to decide the preferred translation.\n",
    "4. Do some smoothing and refining to produce the translated sentence.\n",
    "\n",
    "The downside of a statistical approach is the large amount of parralele texts required and the computing power to analyses them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
